<!doctype html>
<html lang="en">
	<head>
		<title>Music Analytics Project</title>
		<meta charset="utf-8">
		<meta name="description" content="My project">
		<meta name="author" content="William Bird">
		<link rel="stylesheet" type="text/css" href="pages/style.css" media="all"/>
		<link href='http://fonts.googleapis.com/css?family=Lato&subset=latin,latin-ext' rel='stylesheet' type='text/css'>
		<meta name="viewport" content="initial-scale=1">
	</head>
	<body>
		<h1>Music Analytics Project</h1>
		<table class="menu" align="center">
			<tr class="menu">
				<td class="menu"><p><b>Home</b></p></td>
				<td class="menu"><a href="pages/about.html"><p>About</p></a></td>
				<td class="menu"><a href="pages/content.html"><p>Table of Contents</p></a></td>
			</tr>
		</table>
		<br>
		<h2>Notating Musical Scores</h2>
		<p>Below are the notated scores I created for the my project, 
		I choose to create the score for the song <b>'The Unforgiven' by Metallica</b>,
		in addition to that, I also created edited versions of this score. All avaliable below.</p>
		<br>
		<h3>Scores:</h3>
		<ul>
			<li>
				<a href='pages/the_unforgiven/the_unforgiven.html' class="listhead">The Unforgiven Standard Score</a>
			</li>
			<ul>
				<li>
					<h4>Edited Scores:</h4>
				</li>
				<ul>
					<li>
						<a href='pages/the_unforgiven/the_unforgiven_octave_edit.html'>Octave Shifted</a>
					</li>
					<li>
						<a href='pages/the_unforgiven/the_unforgiven_stems_edit.html'>Reversed Stems</a>
					</li>
				</ul>
			</ul>
		</ul>
		<br>
		<h2>Basic Analytics</h2>
		<p>Next, I used the program jSymbolic to create analysis files of 'The Unforgiven'. I also used music21 in python to generate a piano roll 
			and a pitch histogram of 'The Unforgiven'.</p>
		<a href="pages/basic_analytics/jSymbolic/jsymbolic.html"><h3>jSymbolic</h3></a>
		<a href="pages/basic_analytics/music21/music21.html"><h3>music21</h3></a>
		<br>
		<h2>Music as Sound</h2>
		<p>For this task I downloaded 3 copyright free songs of different genres, 
			I then identified and listed the most important metadata. Next I created
			a spectrogram for each of these songs using  SonicVisualizer.
		</p>
		<ul>
			<li>
				<a href="pages/music_as_sound/Good God/good_god.html" class="tracks">Good God</a>
			</li>
			<li>
				<a href="pages/music_as_sound/Moth Man/moth_man.html" class="tracks">Moth Man</a>
			</li>
			<li>	
				<a href="pages/music_as_sound/Searching for Zelda/searching_for_zelda.html" class="tracks">Searching for Zelda</a>
			</li>
		</ul>
		<br>
		<h4>Advantage of time-frequency analysis over waveform analysis</h4>
		<p>
			One of the advantages of time-frequency analysis over waveform-based analysis is that it 
			is possible for humans to see which notes are being played at which times. 
			In waveform-based analysis it is impossible for the human eye to view the wave, and to 
			know what note is being played at any given time. However, in a time-frequency analysis 
			it is possible to see which notes are present. An example of this is with the song 
			‘Good God’ which I created a spectrogram for, in the spectrogram there are a variety of 
			notes at different Hz visible, and we can even see at what times the song includes vocals.
		</p>
		<br>
		<h4>Metadata Associated with these tracks:</h4>
		<a href="pages/music_as_sound/metadata_table.html"><h3>View Table</h3></a>
		<br>
		<h2>Extracting Meaning from Audio</h2>
		<p>For this task I again downloaded 3 songs (I chose to use different 
			songs to the previous task) and exported a Spectrogram, Mel Frequency 
			Coefficients (MFCC), and a Chromagram for each track.
		</p>
		<br>
		<p>After this I used Jupyter notebook in Python to load csv 
			file generated from the MFCCs and the Chromagrams, and use these 
			to create a variety of histograms.
		</p>
		<ul>
			<li>
				<a href="pages/meaning_from_audio/Anata kara toku e (far away from you)/anata_kara.html" class="tracks">Anata kara toku e (Far Away From You)</a>
			</li>
			<li>
				<a href="pages/meaning_from_audio/Eternity/eternity.html" class="tracks">Eternity</a>
			</li>
			<li>	
				<a href="pages/meaning_from_audio/Funk the floor/funk_the_floor.html" class="tracks">Funk the Floor</a>
			</li>
		</ul>
		<h4>Chromagram based Histogram Discussion</h4>
		<p>Looking at the histograms created from the Chromagram .csv files,
		the 3 tracks all seem similar, and they all follow a similar guide of
		where the histograms peak. However, there are differences in the height
		of these peaks. This is most noticeable when comparing the histograms
		generated from Anata kara toku e and for Funk the Floor. When comparing
		these it is not common to see any of the histograms peaking at around
		the same height. However, it is very common to see that a certain
		histogram for one song has a very tall peak, it is likely the same
		histogram for the other song has a very short peak. This comes at
		not surprise as after listening to the music, the songs are completely
		different genres and composted in completely different styles.
		Anata kara toku e being an acoustic guitar with soft vocals and Funk
		the Floor being a bazar mixture of fusion or experimental jazz with
		intermediate distorted vocals. The histograms also show the song Eternity
		often having peaks which are very narrow compared to the other tracks.</p>
		<br>
		<p>When considering the huge variance in genres in these songs,
		it does not come as a surprise that the histograms created show
		differences in the peak heights. However, what is surprising is
		that the peaks are all in roughly the same area of the histogram.</p>
		<br>
		<h2>Similarity and Transcription</h2>
		<p>I first downloaded 3 Blues songs and created similarity graphs comparing 
		the notes used in these songs to Classical and Rock songs based off the notes 
		used. These graphs were created from .csv files derived from Chromagrams 
		of the songs.</p>
		<a href="pages/similarity_transcription/similarity/similarity.html"><h3>Similarity</h3></a>
		<br>
		<p>Next I chose 2 songs to open in MuseScore one of these being the track I used throughout this 
		project 'The Unforgiven' and the other track was a new track I found online, which 
		was the Pokémon Black and White League soundtrack.</p>
		<br>
		<p>For each of these tracks I downloaded the origional MuseScore file, which I then exported 
		as a .wav file. From this .wav file I created a MIDI file which could be loaded back into 
		MuseScore. Click the links below to see the differences in the original files, and those 
		created from a MIDI version of that file (based on its .wav file)</p>
		<a href="pages/similarity_transcription/the_unforgiven/the_unforgiven_transcription.html"><h3>The Unforgiven</h3></a>
		<a href="pages/similarity_transcription/pokemon/pokemon.html"><h3>Pokémon Black and White League Soundtrack</h3></a>
		<br>
		<h4>Comparing the original and digitally transcribed versions</h4>
		<p>With both of the tracks I transcribed using MIDI, the original file and the computer generated files were 
			completely different. First, the files generated from the MIDI cannot be described as anything other than ‘a mess’. 
			With this said, playing the files does sound similar to the original files, but are far from the same, and tend to sound 
			worse throughout the entire track.</p>
		<br>
		<p>Another thing I noticed is the length of the notated music. Creating the MIDI from the .wav file 
			changed the time signature of both pieces, resulting in a different number of bars in each version. 
			This was an extreme difference. In the case of The Unforgiven the original is 76 bars where the MIDI version is 199 bars!</p>
		<br>
		<p>Next, the MIDI generated files also changed which notes were flat by default, 
		making nearly all the notes flat on both tracks I used. Lastly, on the Pokémon file there 
		were many different instruments used in the original; however, the MIDI file only creates 
		tracks using one instrument. This means all of the instruments used were combined into one entity.</p>
	</body>
</html>